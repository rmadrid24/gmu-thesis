% \chapter[Conclusion]{Conclusions}

% In this thesis, we investigated the use of INtel Optane DC Persistent Memory to provide a low-latency and high-throughput storage media for building a serverless storage service that can efficiently handle FaaS workloads. Our study focuses on the limited capability of INtel Optane PMem to handle accesses from multiple concurrent processes and analyzes how these limitations affect the latency and throughput exhibited by the storage media, as well as its ability to meet pre-defined service level agreements, under shifting FaaS workloads. Given the wide hetereoginity of applications running in serverless workloads, this study is focused on two type of applications: interactive applications that demand low latency and batch which demands high throuhgput. WE implement a set of applications to simulate real-world FaaS workloads to gain insights on how to tune the persistent memory device to make it ideal for using with FaaS workloads.

% Our research confirmed that running multiple threads simulating serverless functions degrades the latency and throughput exhibited by the storage media. Similar to what previous works have concluded, this implied that concurrency control must be performed over Optane DC PMem. However, the main finding is that, depending on the applications sharing the persistent memory, the performance degradation can affter some applications more than others. How much the performance degradation affects an application depends on  the performance requirements demande by each application type.

% Our findings suggest that a better approach to control concurrency is to implement independent concurrency levels for each particular type to isolate performance among the different types of applications. Such contention management mechanism must be inline with the goals of an efficient cloud storage serivce, which include transpareent autoscaling and meeting pre-defined service level agreements

% To this end, this works proposes the development of the NVM MIddleware to control the concurrency levels on intel optane pmem to achieve low latency and high throughput for serverless scenarios with interactive and batch applications sharing intel optane dc pmem. OUr experiments show the the NVM MIddleware exhibits performance benefits compared to scenarios with no concurrency or using fixed concurrency levels. First, the NVM MIddleware's workload aware concurrency control mechanism can improve the latency and thrpuhgput of interactive and batch workloads sharing Optane DC PMem by up to 80\% and 90\% respectively, compared to running these applications with no control over Optane. Furthermore, our work demonstrate that a RL model can be designed to implement an agent capable of dynamically tuning the concurrency control optimizations implementef by the NVM MIddleware to meet pre-defined service level agreements. Training the RL agent to tune the NVM Middleware concurrency control under changing workloads works better than keeping a fixed policy all the time.

% In conclusion, this work sheds the light on how to tune the concurrency level on OPtane DC PMem to achieve high performance when used as storage media for FaaS functions. By understanding the limitations of INtel Optane DC PMeme and their implications on FaaS workloads, we can further improve the functionality of the NVM MIddleware. Our methodology has some limitations that can lead to potential future research.

% Intel Optane DC Pmem Optimizations: Besides the number of concurrent threads accessing, Yang et. al. mention other factors that affect the perforance of intel optane dc pmeme. An interesting reseasrch avenue will be to study how these factors affects its performance when tested udner FaaS workloads and learn how the NVM MIddleware can be improved to target these extra limitations.

\chapter{Conclusions and Future Work}

This thesis explored the utilization of Intel Optane DC Persistent Memory to serve as a low-latency and high-throughput storage medium for constructing a serverless storage service capable of efficiently managing Function-as-a-Service (FaaS) workloads. Focusing on the inherent limitations of Intel Optane PMem in handling concurrent processes, we analyzed their impact on storage media latency, throughput, and adherence to predefined service level agreements (SLAs) under varying FaaS workloads. Considering the diverse nature of applications within serverless workloads, our investigation concentrated on two distinct application types: interactive applications requiring low latency and batch applications necessitating high throughput. We developed a set of applications to simulate real-world FaaS workloads, aiming to glean insights into optimizing persistent memory device configurations for FaaS usage scenarios.

Our research confirmed that running multiple threads to simulate serverless functions results in degraded latency and throughput performance of the storage media. Consistent with prior studies, this underscores the necessity of implementing concurrency control mechanisms over Optane DC PMem. Notably, we found that the performance degradation may disproportionately affect certain applications, depending on their specific performance requirements.

Our findings advocate for a nuanced approach to concurrency control, suggesting the implementation of independent concurrency levels tailored to each application type to mitigate performance interference interactive and batch applications. Such contention management mechanisms must align with the objectives of an efficient cloud storage service, encompassing transparent autoscaling and the fulfillment of predefined SLAs.

To address these challenges, we propose the development of the NVM Middleware to regulate concurrency levels on Intel Optane PMem, catering to low-latency and high-throughput demands in serverless scenarios involving interactive and batch applications sharing this storage medium. Our experiments demonstrate that the NVM Middleware yields performance benefits compared to scenarios lacking concurrency control or utilizing fixed concurrency levels. Specifically, our middleware's workload-aware concurrency control mechanism can enhance the latency and throughput of interactive and batch workloads sharing Optane DC PMem by up to 80\% and 90\%, respectively, compared to scenarios with no concurrency control. Furthermore, our work illustrates the efficacy of a Reinforcement Learning (RL) agent in dynamically tuning concurrency control optimizations implemented by the NVM Middleware to meet predefined SLAs. Training the RL agent to adapt the NVM Middleware's concurrency control to changing workloads outperforms static policy approaches.

In conclusion, this thesis illuminates strategies for optimizing concurrency levels on Optane DC PMem to achieve peak performance when utilized as storage media for FaaS functions. By comprehending the limitations of Intel Optane DC PMem and their ramifications on FaaS workloads, we can refine the functionality of the NVM Middleware.

\subsection*{Future Research Directions}

This section delves into the limitations inherent in our methodology and the insights gleaned from the findings presented. Subsequently, potential avenues for future research are explored in light of these limitations.

\textbf{Storage Service Integration:} Originally, this thesis aimed to design a simple storage server facilitating communication with applications via Remote Procedure Calls (RPC), leveraging the NVM Middleware to optimize Intel Optane DC PMem performance. However, our measurements were affected by network overhead in the infrastructure housing the server with Optane DC PMem. Thus, evaluating the NVM Middleware on a real-world serverless storage service remains a future research endeavor. Anna key-value database \cite{wu2019anna} proposes a promising option for assessing the NVM Middleware by extending it to incorporate a storage tier based on Optane DC PMem, thereby utilizing the NVM Middleware as the optimization layer for persistent memory.

\textbf{Reducing Autoscaling Overhead:} Our current approach to scaling resources involves adding or removing up to two threads per one-second window, which may delay the system's adaptation to the optimal combination of interactive and batch threads. This delay could contribute to performance spikes observed in the results. An intriguing avenue for exploration is enabling the NVM Middleware to add or remove more than two threads per time step to expedite adaptation to workload changes, potentially enhancing SLA fulfillment efficiency. However, this approach may introduce additional actions in the action space, increasing the RL model's complexity.

\textbf{Choice of Workloads:} While YCSB offers versatility in testing various workloads, its simulations may not accurately reflect real-world serverless workload characteristics. Thus, in this thesis, we rely on I/O traces from actual serverless platforms to evaluate our RL approach. However, crafting experimental workloads based on real-world serverless traces, with modified characteristics such as block size and read-to-write ratio, was necessary to test the RL agent's autoscaling capabilities under shifting workloads. Yet, our chosen workloads may have hindered the RL agent's ability to meet latency SLAs. Obtaining more real-world serverless traces could shed light on the NVM Middleware's limitations and capabilities. However, acquiring such traces is challenging and time-consuming, as the RL agent must undergo the entire learning process for each stage, from dataset generation for model selection to running Q-learning episodes.

\textbf{Exploring Other Function Approximation Techniques:} Feature extraction is pivotal but complex. While we select relevant features for our RL model, covering more generic use cases may necessitate additional features to enhance learning capabilities. These features could encompass workload characteristics, NVM Middleware metrics, Optane DC PMem internal metrics, and general server metrics like CPU and memory usage. Limitations in feature representation may impede linear function approximators' efficacy \cite{russel2020ai}. Alternatively, employing deep neural networks for function approximation \cite{Quantit3:online}, known as deep reinforcement learning, could address these challenges. Deep reinforcement learning has demonstrated success in complex scenarios by autonomously discovering useful features, as evidenced in gaming environments \cite{mnih2013playing,silver2017mastering}.

\textbf{Learning Workload Characteristics:} The current strategy employed by the NVM Middleware involves utilizing predefined hints regarding workload characteristics to allocate requests to specific queues. However, this approach may encounter scalability challenges, prompting the exploration of autonomous learning methods for workload characteristics. Several approaches can be considered, ranging from straightforward categorization based on predefined criteria to more sophisticated methods leveraging machine learning models.

\textbf{Intel Optane DC PMem Optimizations:} Beyond the number of concurrent threads accessing Optane DC PMem, as highlighted by Yang et al., additional factors influence the performance of Intel Optane DC PMem. An intriguing avenue for future research involves investigating how these factors impact performance under FaaS workloads and discerning ways to enhance the NVM Middleware to address these supplementary limitations.