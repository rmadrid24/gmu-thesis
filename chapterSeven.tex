% \chapter[Conclusion]{Conclusions}

% In this thesis, we investigated the use of INtel Optane DC Persistent Memory to provide a low-latency and high-throughput storage media for building a serverless storage service that can efficiently handle FaaS workloads. Our study focuses on the limited capability of INtel Optane PMem to handle accesses from multiple concurrent processes and analyzes how these limitations affect the latency and throughput exhibited by the storage media, as well as its ability to meet pre-defined service level agreements, under shifting FaaS workloads. Given the wide hetereoginity of applications running in serverless workloads, this study is focused on two type of applications: interactive applications that demand low latency and batch which demands high throuhgput. WE implement a set of applications to simulate real-world FaaS workloads to gain insights on how to tune the persistent memory device to make it ideal for using with FaaS workloads.

% Our research confirmed that running multiple threads simulating serverless functions degrades the latency and throughput exhibited by the storage media. Similar to what previous works have concluded, this implied that concurrency control must be performed over Optane DC PMem. However, the main finding is that, depending on the applications sharing the persistent memory, the performance degradation can affter some applications more than others. How much the performance degradation affects an application depends on  the performance requirements demande by each application type.

% Our findings suggest that a better approach to control concurrency is to implement independent concurrency levels for each particular type to isolate performance among the different types of applications. Such contention management mechanism must be inline with the goals of an efficient cloud storage serivce, which include transpareent autoscaling and meeting pre-defined service level agreements

% To this end, this works proposes the development of the NVM MIddleware to control the concurrency levels on intel optane pmem to achieve low latency and high throughput for serverless scenarios with interactive and batch applications sharing intel optane dc pmem. OUr experiments show the the NVM MIddleware exhibits performance benefits compared to scenarios with no concurrency or using fixed concurrency levels. First, the NVM MIddleware's workload aware concurrency control mechanism can improve the latency and thrpuhgput of interactive and batch workloads sharing Optane DC PMem by up to 80\% and 90\% respectively, compared to running these applications with no control over Optane. Furthermore, our work demonstrate that a RL model can be designed to implement an agent capable of dynamically tuning the concurrency control optimizations implementef by the NVM MIddleware to meet pre-defined service level agreements. Training the RL agent to tune the NVM Middleware concurrency control under changing workloads works better than keeping a fixed policy all the time.

% In conclusion, this work sheds the light on how to tune the concurrency level on OPtane DC PMem to achieve high performance when used as storage media for FaaS functions. By understanding the limitations of INtel Optane DC PMeme and their implications on FaaS workloads, we can further improve the functionality of the NVM MIddleware. Our methodology has some limitations that can lead to potential future research.

% Intel Optane DC Pmem Optimizations: Besides the number of concurrent threads accessing, Yang et. al. mention other factors that affect the perforance of intel optane dc pmeme. An interesting reseasrch avenue will be to study how these factors affects its performance when tested udner FaaS workloads and learn how the NVM MIddleware can be improved to target these extra limitations.

\chapter{Conclusions}

This thesis explored the utilization of Intel Optane DC Persistent Memory (Optane PMem) to serve as a low-latency and high-throughput storage medium for constructing a serverless storage service capable of efficiently managing Function-as-a-Service (FaaS) workloads. Focusing on the inherent limitations of Optane PMem in handling concurrent processes, we analyzed their impact on storage media latency, throughput, and adherence to predefined service level agreements (SLAs) under varying FaaS workloads. Considering the diverse nature of applications within serverless workloads, our investigation concentrated on two distinct application types: interactive applications requiring low latency and batch applications necessitating high throughput. We developed a set of applications to simulate real-world FaaS workloads, aiming to glean insights into optimizing Optane PMem for FaaS usage scenarios.

Our research confirmed that running multi-threaded applications simulating serverless workloads results in degraded latency and throughput performance of persistent memory. Consistent with prior studies, this underscores the necessity of implementing concurrency control mechanisms over Optane PMem. Notably, we found that the performance degradation may disproportionately affect certain applications, depending on their specific performance requirements.

Our findings advocate for a nuanced approach to concurrency control, suggesting the implementation of independent concurrency levels tailored to each application type to mitigate performance interference among interactive and batch applications. Such contention management mechanisms must align with the objectives of an efficient cloud storage service, encompassing transparent autoscaling and the fulfillment of predefined SLAs.

To address these challenges, we propose the development of the NVM Middleware to regulate concurrency levels on Intel PMem, catering to low-latency and high-throughput demands in serverless scenarios involving interactive and batch applications sharing this storage medium. Our experiments demonstrate that the NVM Middleware yields performance benefits compared to scenarios lacking concurrency control or utilizing fixed concurrency levels. Specifically, our middleware's workload-aware concurrency control mechanism can enhance the latency and throughput of interactive and batch workloads sharing Optane DC PMem by up to 80\% and 90\%, respectively, compared to scenarios with no concurrency control. 

% Furthermore, our work proposes a RL model that efficiently captures the dynamics of a storage media handling requests from FaaS workloads. Using this mdoel, our work illustrates the efficacy of a Reinforcement Learning (RL) agent in dynamically tuning concurrency control optimizations implemented by the NVM Middleware to meet predefined SLAs. Training the RL agent to adapt the NVM Middleware's concurrency control to changing workloads outperforms static policy approaches.

Moreover, our research introduces a reinforcement learning (RL) model designed to effectively capture the intricacies of storage media managing requests from FaaS workloads. With this model, we train an RL agent to dynamically adjust the concurrency control mechanisms implemented by the NVM Middleware in response to workload changes, ensuring adherence to predefined SLAs. Our work illustrates that the RL agent surpasses static policy approaches in performance and adherence to predefined SLAs.

In conclusion, this thesis illuminates strategies for optimizing concurrency levels on Optane DC PMem to achieve peak performance when utilized as storage media for FaaS workloads. By comprehending the limitations of Optane PMem and their ramifications on FaaS workloads, we can refine the functionality of the NVM Middleware.