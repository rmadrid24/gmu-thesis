% \appchapter[RL Phases]{RL Phase}
% \label{appendix:c}

% We build four distinct phases to test if the RL agent find the right combination of threads for each phase that maximizes performance and meets predefined SLA metrics. To build the interactive and batch application for each phase, we use as a base the traces collected from Azure Functions and Wukong. We build different workloads by modifying the data access size, read-to-write ratio of these traces, as well as the client threads configured to run each applicatoin. Furthremore, we increase the pace of the traces to intensify the amount of concurrent requests sent to the NVM MIddleware. Additionally, we execute the traces in a loop, in case there are more simulation steps than requests in the traces.

% We build the following phases to test the RL train:

% Phase 1. We collect 2039 requests from the Azure Function blob accesses traces to run as our interactive workload. These requests occur in December 6, 2020, between 8:10pm and 8:22pm. The requests collected are predominated by reads, exhibiting a read-to-write ratio of 80-20. They are also predominated by small data access sizes betwen 30B and 50B. For the batch workload, we collect a portion (3847 requests) of the SVD traces. We set a read-to-write ratio of 50-50 and a fixed data access size of 800KB. Furthremore, we assign 200 client threads for both applications to serve requests concurrently. 

% Phase 2. The interactive workload remains the same as Phase 1, except we reduce the client threads to 150. Similarly, the batch workload remains the same, except we increase the concurrent client threads to 320.  

% Phase 3. The interactive workload remains the same as Phase 1, except we increase the client threads to 400. FOr the batch workload, we change the collected SVD traces to use a fixed data access size of 4k and change the workload to be pure read. Furthremore, we assign 200 client threads to the batch workload.

% Phase 4. Phase 1. We collect 7814 requests from the Azure Function blob accesses traces to run as our interactive workload. These requests occur in December 6, 2020, between 1:21pm and 1:27pm. The requests collected are predominated by writes, exhibiting a read-to-write ratio of 10-90. They are also predominated by larger data access sizes around 500B. The batch workload remains the same as Phase 3. Furthremore, we assign 200 client threads for each application.

\appchapter[Reinforcement Learning Phases]{Reinforcement Learning Phases}
\label{appendix:c}

To evaluate the learning capabilities of the RL agent in adapting thread combinations for optimal performance and meeting predefined SLA metrics, we design four distinct phases. Leveraging I/O traces collected from Azure Functions and Wukong, we construct interactive and batch workloads by adjusting parameters such as data access size, read-to-write ratio, and client threads for each application. We intensify the workload by accelerating the pace of the traces and loop the execution to ensure sufficient simulation steps.

The phases are structured as follows:

\textbf{Phase 1:} We utilize 2039 requests from Azure Function blob access traces captured on December 6, 2020, between 8:20 PM and 8:22 PM. These requests are primarily reads, with a read-to-write ratio of 80-20 and data access sizes ranging between 30B and 50B. For the batch workload, we employ a subset of SVD traces comprising 3847 requests, maintaining a 50-50 read-to-write ratio and a fixed data access size of 800KB. Both applications are configured with 200 client threads for concurrent request handling.

\textbf{Phase 2:} The interactive workload remains unchanged from Phase 1, while the number of client threads is reduced to 150. Similarly, the batch workload maintains its configuration but with an increased number of concurrent client threads set to 320.

\textbf{Phase 3:} The interactive workload is consistent with Phase 1, but with an escalation in client threads to 400. For the batch workload, we modify the SVD traces to employ a fixed data access size of 4k and transition to a read-only workload. Concurrently, we assign 200 client threads for the batch workload.

\textbf{Phase 4:} Drawing from Azure Function blob access traces, we incorporate 7814 requests occurring on December 6, 2020, between 1:21 PM and 1:27 PM for the interactive workload. These requests are predominantly writes, with a read-to-write ratio of 10-90 and larger data access sizes averaging around 500B. The batch workload configuration remains consistent with Phase 3. Each application is allocated 200 client threads for concurrent request processing.


% We change the interactive traces to use a data access size of 50B, a read-to-write ratio of 80-20, and 200 concurrent client threads. We change the batch traces to use a data access size of 8k, read-to-write ratio of 50-50, and 200 concurrent client threads.

% We change the interactive traces to use a data access size of 50B, a read-to-write ratio of 80-20, and 150 concurrent client threads. We change the batch traces to use a data access size of 8k, read-to-write ratio of 50-50, and 320 concurrent client threads.

% We change the interactive traces to use a data access size of 50B, a read-to-write ratio of 80-20, and 400 concurrent client threads. We change the batch traces to use a data access size of 4k, pure read, and 200 concurrent client threads.  

% We change the interactive traces to use a data access size of 500B, a read-to-write ratio of 10-90, and 200 concurrent client threads. We change the batch traces to use a data access size of 4k, pure read, and 200 concurrent client threads. 